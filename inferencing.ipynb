{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebebdeca-b28b-4a87-9477-8134cf3b622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_video(DIR_TEST, vidName, model):\n",
    "    vid = cv2.VideoCapture(DIR_TEST)\n",
    "    property_id = int(cv2.CAP_PROP_FRAME_COUNT) \n",
    "    NUM_FRAMES = int(cv2.VideoCapture.get(vid, property_id))\n",
    "    idx = 1\n",
    "    frame_width = int(vid.get(3))\n",
    "    frame_height = int(vid.get(4))\n",
    "    # Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
    "    out = cv2.VideoWriter(vidName,cv2.VideoWriter_fourcc('M','J','P','G'), 30, (frame_width,frame_height))\n",
    "    classes = [None] * NUM_FRAMES\n",
    "    bboxes = [None] * NUM_FRAMES\n",
    "    \n",
    "    while vid.isOpened():\n",
    "        ret, image = vid.read()\n",
    "        \n",
    "        orig_image = image.copy()\n",
    "        # BGR to RGB\n",
    "        image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        # make the pixel range between 0 and 1\n",
    "        image /= 255.0\n",
    "        # bring color channels to front\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(float)\n",
    "        # convert to tensor\n",
    "        image = torch.tensor(image, dtype=torch.float).cuda()\n",
    "        # add batch dimension\n",
    "        image = torch.unsqueeze(image, 0)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image)\n",
    "        \n",
    "        # load all detection to CPU for further operations\n",
    "        outputs = [{k: v.to('cpu') for k, v in t.items()} for t in outputs]\n",
    "        # carry further only if there are detected boxes\n",
    "        if len(outputs[0]['boxes']) != 0:\n",
    "            boxes = outputs[0]['boxes'].data.numpy()\n",
    "            scores = outputs[0]['scores'].data.numpy()\n",
    "            \n",
    "            # filter out boxes according to `detection_threshold`\n",
    "            boxes = boxes[scores >= detection_threshold].astype(np.int32)\n",
    "            bboxes[idx] = boxes\n",
    "            draw_boxes = bboxes[idx].copy() \n",
    "             \n",
    "            # get all the predicited class names\n",
    "            pred_classes = [CLASSES[i] for i in outputs[0]['labels'].cpu().numpy()]\n",
    "            pred_classes = np.array(pred_classes)\n",
    "            pred_classes = pred_classes[scores >= detection_threshold]\n",
    "            classes[idx] = pred_classes\n",
    "            # draw the bounding boxes and write the class name on top of it\n",
    "            for j, box in enumerate(draw_boxes):\n",
    "                cv2.rectangle(orig_image,\n",
    "                            (int(box[0]), int(box[1])),\n",
    "                            (int(box[2]), int(box[3])),\n",
    "                            (0, 0, 255), 2)\n",
    "                cv2.putText(orig_image, str(pred_classes[j]), \n",
    "                            (int(box[0]), int(box[1]-5)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), \n",
    "                            2, lineType=cv2.LINE_AA)\n",
    "            out.write(orig_image)\n",
    "        idx += 1\n",
    "        print(f\"Image {idx+1} done...\")\n",
    "        print('-'*50)\n",
    "        if idx == NUM_FRAMES:\n",
    "            vid.release()\n",
    "            out.release()\n",
    "    print('TEST PREDICTIONS COMPLETE') \n",
    "    return [bboxes, classes]\n",
    "\n",
    "def inference_images(DIR_TEST, model, OUT_DIR):\n",
    "    imagePath = glob.glob(f\"{DIR_TEST}/*.png\")\n",
    "    all_images = [image_path.split('\\\\')[-1] for image_path in imagePath]\n",
    "    all_images = sorted(all_images)\n",
    "    num_images = len(all_images)\n",
    "    classes = [None] * num_images\n",
    "    bboxes = [None] * num_images\n",
    "    \n",
    "    for idx, el in enumerate(all_images):\n",
    "        image = read_image(el)\n",
    "        \n",
    "        orig_image = cv2.imread(el)\n",
    "        # BGR to RGB\n",
    "        image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        # make the pixel range between 0 and 1\n",
    "        image /= 255.0\n",
    "        # bring color channels to front\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(float)\n",
    "        # convert to tensor\n",
    "        image = torch.tensor(image, dtype=torch.float).cuda()\n",
    "        # add batch dimension\n",
    "        image = torch.unsqueeze(image, 0)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image)\n",
    "        \n",
    "        # load all detection to CPU for further operations\n",
    "        outputs = [{k: v.to('cpu') for k, v in t.items()} for t in outputs]\n",
    "        # carry further only if there are detected boxes\n",
    "        if len(outputs[0]['boxes']) != 0:\n",
    "            boxes = outputs[0]['boxes'].data.numpy()\n",
    "            scores = outputs[0]['scores'].data.numpy()\n",
    "            \n",
    "            # filter out boxes according to `detection_threshold`\n",
    "            boxes = boxes[scores >= detection_threshold].astype(np.int32)\n",
    "            bboxes[idx] = boxes\n",
    "            draw_boxes = bboxes[idx].copy() \n",
    "             \n",
    "            # get all the predicited class names\n",
    "            pred_classes = [CLASSES[i] for i in outputs[0]['labels'].cpu().numpy()]\n",
    "            pred_classes = np.array(pred_classes)\n",
    "            pred_classes = pred_classes[scores >= detection_threshold]\n",
    "            classes[idx] = pred_classes\n",
    "            # draw the bounding boxes and write the class name on top of it\n",
    "            for j, box in enumerate(draw_boxes):\n",
    "                cv2.rectangle(orig_image,\n",
    "                            (int(box[0]), int(box[1])),\n",
    "                            (int(box[2]), int(box[3])),\n",
    "                            (0, 0, 255), 2)\n",
    "                cv2.putText(orig_image, str(pred_classes[j]), \n",
    "                            (int(box[0]), int(box[1]-5)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), \n",
    "                            2, lineType=cv2.LINE_AA)\n",
    "            cv2.imwrite(el, orig_image) #The 'el' filepath is broken right now (TODO: FIX) \n",
    "\n",
    "        print(f\"Image {idx+1} done...\")\n",
    "        print('-'*50)\n",
    "\n",
    "    print('TEST PREDICTIONS COMPLETE') \n",
    "    return [bboxes, classes]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
